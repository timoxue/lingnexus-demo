"""LingNexus æ¨¡å‹å¯¹æ¯”å›¾å½¢ç•Œé¢

åŒæ—¶ä½¿ç”¨å¤šä¸ªæ¨¡å‹ï¼ˆQwen-Max, Gemini, DeepSeekï¼‰ç”Ÿæˆåˆ†å­å¹¶å¯¹æ¯”æ€§èƒ½
"""

try:
    import gradio as gr
except ImportError:
    print("é”™è¯¯ï¼šæœªå®‰è£… Gradioã€‚è¯·è¿è¡Œï¼špip install gradio")
    exit(1)

import agentscope
from agentscope.message import Msg
from agents.molecule_designer import create_molecule_designer_agent
from tools.chem_tools import admet_filter, calculate_molecular_properties
import re
import time
from typing import List, Tuple, Dict


# åˆå§‹åŒ–æ ‡å¿—
_initialized = False


def initialize_agentscope():
    """åˆå§‹åŒ– AgentScopeï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
    global _initialized
    if not _initialized:
        agentscope.init(
            model_configs="./config/model_config.json",
            project="LingNexus",
            save_code=False,
            save_api_invoke=False,
        )
        _initialized = True


def parse_smiles_from_response(response_text: str) -> List[str]:
    """ä»æ™ºèƒ½ä½“å“åº”ä¸­æå– SMILES"""
    lines = response_text.strip().split('\n')
    smiles_list = []
    
    for line in lines:
        line = line.strip()
        if not line or 'è¯·æä¾›' in line or len(line) < 5:
            continue
        line = re.sub(r'^[\d\-\.\)]+\s*', '', line)
        
        if line and not line.startswith(('#', '//')):
            smiles_list.append(line)
    
    return smiles_list


def compare_models_ui(
    target_name: str,
    model1: str,
    model2: str,
    requirements: str,
    progress=gr.Progress()
) -> Tuple[str, str, str]:
    """å›¾å½¢ç•Œé¢ï¼šå¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„åˆ†å­ç”Ÿæˆèƒ½åŠ›
    
    Returns:
        Tuple[str, str, str]: (å¯¹æ¯”æŠ¥å‘Š, æ¨¡å‹1ç»“æœ, æ¨¡å‹2ç»“æœ)
    """
    
    if not target_name.strip():
        return "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥é¶ç‚¹åç§°", "", ""
    
    try:
        # åˆå§‹åŒ–
        progress(0.05, desc="åˆå§‹åŒ– AgentScope...")
        initialize_agentscope()
        
        # å‡†å¤‡è¯·æ±‚
        user_request = f"è®¾è®¡ {target_name} æŠ‘åˆ¶å‰‚"
        if requirements:
            user_request += f"ï¼Œ{requirements}"
        
        models = [model1, model2]
        results = {}
        
        # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
        for idx, model_name in enumerate(models):
            progress_val = 0.1 + (idx * 0.4)
            progress(progress_val, desc=f"æ­£åœ¨æµ‹è¯• {model_name.upper()}...")
            
            try:
                # åˆ›å»ºæ™ºèƒ½ä½“
                designer = create_molecule_designer_agent(model_config_name=model_name)
                
                # ç”Ÿæˆåˆ†å­
                start_time = time.time()
                user_msg = Msg(name="User", content=user_request, role="user")
                designer_response = designer(user_msg)
                end_time = time.time()
                
                generation_time = end_time - start_time
                
                # è§£æ SMILES
                smiles_list = parse_smiles_from_response(designer_response.content)
                
                if not smiles_list:
                    results[model_name] = {
                        "success": False,
                        "error": "æ— æ³•æå– SMILES",
                        "raw_response": designer_response.content
                    }
                    continue
                
                # ADMET è¯„ä¼°
                passed_molecules = admet_filter(smiles_list, verbose=False)
                
                # è®¡ç®—ç»Ÿè®¡
                pass_rate = len(passed_molecules) / len(smiles_list) * 100 if smiles_list else 0
                
                if passed_molecules:
                    avg_mw = sum(m['properties']['molecular_weight'] for m in passed_molecules) / len(passed_molecules)
                    avg_qed = sum(m['properties']['qed'] for m in passed_molecules) / len(passed_molecules)
                    avg_logp = sum(m['properties']['logp'] for m in passed_molecules) / len(passed_molecules)
                else:
                    avg_mw = avg_qed = avg_logp = 0
                
                results[model_name] = {
                    "success": True,
                    "generated_count": len(smiles_list),
                    "passed_count": len(passed_molecules),
                    "pass_rate": pass_rate,
                    "generation_time": generation_time,
                    "smiles_list": smiles_list,
                    "passed_molecules": passed_molecules,
                    "avg_mw": avg_mw,
                    "avg_qed": avg_qed,
                    "avg_logp": avg_logp,
                    "raw_response": designer_response.content
                }
                
            except Exception as e:
                results[model_name] = {
                    "success": False,
                    "error": str(e)
                }
        
        progress(0.95, desc="ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        report = generate_comparison_report(target_name, models, results)
        
        # ç”Ÿæˆè¯¦ç»†ç»“æœ
        model1_detail = generate_model_detail(model1, results.get(model1, {}))
        model2_detail = generate_model_detail(model2, results.get(model2, {}))
        
        progress(1.0, desc="å®Œæˆï¼")
        
        return report, model1_detail, model2_detail
        
    except Exception as e:
        return f"âŒ é”™è¯¯ï¼š{str(e)}", "", ""


def generate_comparison_report(target_name: str, models: List[str], results: Dict) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š"""
    
    report = f"""# ğŸ”¬ æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š

**é¶ç‚¹**: {target_name}  
**å¯¹æ¯”æ¨¡å‹**: {models[0].upper()} vs {models[1].upper()}

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”è¡¨

| æŒ‡æ ‡ | {models[0].upper()} | {models[1].upper()} | ä¼˜åŠ¿ |
|------|---------|---------|------|
"""
    
    # æå–ç»“æœ
    r1 = results.get(models[0], {})
    r2 = results.get(models[1], {})
    
    if r1.get("success") and r2.get("success"):
        # ç”Ÿæˆæ•°é‡
        winner = "ğŸ†" if r1['generated_count'] >= r2['generated_count'] else ""
        winner2 = "ğŸ†" if r2['generated_count'] > r1['generated_count'] else ""
        report += f"| ç”Ÿæˆåˆ†å­æ•° | {r1['generated_count']} {winner} | {r2['generated_count']} {winner2} | {'å¹³å±€' if winner == winner2 else (models[0].upper() if winner else models[1].upper())} |\n"
        
        # é€šè¿‡æ•°é‡
        winner = "ğŸ†" if r1['passed_count'] >= r2['passed_count'] else ""
        winner2 = "ğŸ†" if r2['passed_count'] > r1['passed_count'] else ""
        report += f"| é€šè¿‡ç­›é€‰æ•° | {r1['passed_count']} {winner} | {r2['passed_count']} {winner2} | {'å¹³å±€' if winner == winner2 else (models[0].upper() if winner else models[1].upper())} |\n"
        
        # é€šè¿‡ç‡
        winner = "ğŸ†" if r1['pass_rate'] >= r2['pass_rate'] else ""
        winner2 = "ğŸ†" if r2['pass_rate'] > r1['pass_rate'] else ""
        report += f"| é€šè¿‡ç‡ | {r1['pass_rate']:.1f}% {winner} | {r2['pass_rate']:.1f}% {winner2} | {'å¹³å±€' if abs(r1['pass_rate'] - r2['pass_rate']) < 1 else (models[0].upper() if winner else models[1].upper())} |\n"
        
        # å¹³å‡ QED
        if r1['passed_count'] > 0 and r2['passed_count'] > 0:
            winner = "ğŸ†" if r1['avg_qed'] >= r2['avg_qed'] else ""
            winner2 = "ğŸ†" if r2['avg_qed'] > r1['avg_qed'] else ""
            report += f"| å¹³å‡ç±»è¯æ€§(QED) | {r1['avg_qed']:.3f} {winner} | {r2['avg_qed']:.3f} {winner2} | {models[0].upper() if winner else models[1].upper()} |\n"
        
        # å¹³å‡åˆ†å­é‡
        if r1['passed_count'] > 0 and r2['passed_count'] > 0:
            winner = "âœ“" if abs(r1['avg_mw'] - 400) <= abs(r2['avg_mw'] - 400) else ""
            winner2 = "âœ“" if abs(r2['avg_mw'] - 400) < abs(r1['avg_mw'] - 400) else ""
            report += f"| å¹³å‡åˆ†å­é‡(MW) | {r1['avg_mw']:.1f} {winner} | {r2['avg_mw']:.1f} {winner2} | {models[0].upper() if winner else models[1].upper()} |\n"
        
        # ç”Ÿæˆé€Ÿåº¦
        winner = "ğŸ†" if r1['generation_time'] <= r2['generation_time'] else ""
        winner2 = "ğŸ†" if r2['generation_time'] < r1['generation_time'] else ""
        report += f"| ç”Ÿæˆé€Ÿåº¦(ç§’) | {r1['generation_time']:.2f} {winner} | {r2['generation_time']:.2f} {winner2} | {models[0].upper() if winner else models[1].upper()} |\n"
        
        report += "\n---\n\n"
        
        # è¾“å‡ºæ ¼å¼è´¨é‡
        report += "## ğŸ“ è¾“å‡ºæ ¼å¼è´¨é‡\n\n"
        
        for model_name in models:
            r = results[model_name]
            raw_text = r['raw_response']
            
            has_explanation = any(keyword in raw_text for keyword in 
                                 ['åˆ†å­', 'æŠ‘åˆ¶å‰‚', 'è®¾è®¡', 'å…·æœ‰', 'è¯¥', 'è¿™', 'å¯ä»¥', 'The', 'This'])
            has_numbering = bool(re.search(r'^\d+[\.\)ã€]', raw_text, re.MULTILINE))
            
            report += f"**{model_name.upper()}**: "
            if not has_explanation and not has_numbering:
                report += "âœ… ä¼˜ç§€ï¼ˆçº¯ SMILESï¼Œæ— è§£é‡Šï¼‰\n\n"
            elif not has_explanation:
                report += "âš ï¸ è‰¯å¥½ï¼ˆæœ‰ç¼–å·ï¼Œä½†æ— è§£é‡Šï¼‰\n\n"
            else:
                report += "âš ï¸ ä¸€èˆ¬ï¼ˆåŒ…å«è§£é‡Šæ€§æ–‡å­—ï¼‰\n\n"
        
        report += "---\n\n"
        
        # ç»¼åˆè¯„åˆ†
        report += "## ğŸ† ç»¼åˆè¯„åˆ†\n\n"
        
        scores = {}
        for model in models:
            r = results[model]
            # ç»¼åˆè¯„åˆ†ï¼šé€šè¿‡ç‡(40%) + QED(30%) + é€Ÿåº¦(30%)
            score = (r['pass_rate'] / 100) * 40
            if r['passed_count'] > 0:
                score += (r['avg_qed'] / 1.0) * 30
            # é€Ÿåº¦åˆ†æ•°ï¼ˆè¶Šå¿«è¶Šå¥½ï¼‰
            max_time = max(r1['generation_time'], r2['generation_time'])
            if max_time > 0:
                score += (1 - r['generation_time'] / max_time) * 30
            scores[model] = score
        
        for model in models:
            report += f"- **{model.upper()}**: {scores[model]:.1f} åˆ†\n"
        
        best_model = max(scores, key=lambda k: scores[k])
        report += f"\n**ğŸ¯ æ¨è**: {best_model.upper()}\n\n"
        
        # ä½¿ç”¨å»ºè®®
        report += "---\n\n## ğŸ’¡ ä½¿ç”¨å»ºè®®\n\n"
        
        if r1['pass_rate'] > r2['pass_rate'] + 10:
            report += f"- **{models[0].upper()}** é€šè¿‡ç‡æ˜æ˜¾æ›´é«˜ï¼Œé€‚åˆéœ€è¦å¤§é‡é«˜è´¨é‡å€™é€‰ç‰©çš„åœºæ™¯\n"
        elif r2['pass_rate'] > r1['pass_rate'] + 10:
            report += f"- **{models[1].upper()}** é€šè¿‡ç‡æ˜æ˜¾æ›´é«˜ï¼Œé€‚åˆéœ€è¦å¤§é‡é«˜è´¨é‡å€™é€‰ç‰©çš„åœºæ™¯\n"
        
        if r1['generation_time'] < r2['generation_time'] * 0.7:
            report += f"- **{models[0].upper()}** é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œæ‰¹é‡ç”Ÿæˆ\n"
        elif r2['generation_time'] < r1['generation_time'] * 0.7:
            report += f"- **{models[1].upper()}** é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œæ‰¹é‡ç”Ÿæˆ\n"
        
        if r1['passed_count'] > 0 and r2['passed_count'] > 0:
            if r1['avg_qed'] > r2['avg_qed'] + 0.05:
                report += f"- **{models[0].upper()}** å¹³å‡ç±»è¯æ€§æ›´å¥½ï¼Œé€‚åˆè´¨é‡ä¼˜å…ˆçš„ç­›é€‰\n"
            elif r2['avg_qed'] > r1['avg_qed'] + 0.05:
                report += f"- **{models[1].upper()}** å¹³å‡ç±»è¯æ€§æ›´å¥½ï¼Œé€‚åˆè´¨é‡ä¼˜å…ˆçš„ç­›é€‰\n"
    
    else:
        # æœ‰æ¨¡å‹å¤±è´¥
        for model in models:
            r = results.get(model, {})
            if not r.get("success"):
                report += f"\nâŒ **{model.upper()}** è¿è¡Œå¤±è´¥: {r.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
    
    return report


def generate_model_detail(model_name: str, result: Dict) -> str:
    """ç”Ÿæˆå•ä¸ªæ¨¡å‹çš„è¯¦ç»†ç»“æœ"""
    
    if not result.get("success"):
        return f"""# âŒ {model_name.upper()} - è¿è¡Œå¤±è´¥

**é”™è¯¯**: {result.get('error', 'æœªçŸ¥é”™è¯¯')}

---

## åŸå§‹å“åº”

```
{result.get('raw_response', 'æ— å“åº”')}
```
"""
    
    detail = f"""# ğŸ¤– {model_name.upper()} - è¯¦ç»†ç»“æœ

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **ç”Ÿæˆåˆ†å­æ•°**: {result['generated_count']}
- **é€šè¿‡ç­›é€‰æ•°**: {result['passed_count']}
- **é€šè¿‡ç‡**: {result['pass_rate']:.1f}%
- **ç”Ÿæˆè€—æ—¶**: {result['generation_time']:.2f} ç§’

---

## ğŸ§ª ç”Ÿæˆçš„ SMILES

"""
    
    for idx, smi in enumerate(result['smiles_list'], 1):
        detail += f"{idx}. `{smi}`\n"
    
    detail += "\n---\n\n## âœ… é€šè¿‡ ADMET ç­›é€‰çš„åˆ†å­\n\n"
    
    if result['passed_molecules']:
        for idx, mol_data in enumerate(result['passed_molecules'], 1):
            props = mol_data['properties']
            detail += f"""
### åˆ†å­ {idx}

**SMILES**: `{mol_data['smiles']}`

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| åˆ†å­é‡ (MW) | {props['molecular_weight']:.1f} Da | {'âœ…' if props['molecular_weight'] < 500 else 'âš ï¸'} |
| ç±»è¯æ€§ (QED) | {props['qed']:.3f} | {'âœ…' if props['qed'] > 0.6 else 'âš ï¸'} |
| LogP | {props['logp']:.2f} | {'âœ…' if 1 <= props['logp'] <= 5 else 'âš ï¸'} |
| TPSA | {props['tpsa']:.1f} Å² | {'âœ…' if props['tpsa'] < 140 else 'âš ï¸'} |
| å¯æ—‹è½¬é”® | {props['rotatable_bonds']} | {'âœ…' if props['rotatable_bonds'] < 10 else 'âš ï¸'} |

---
"""
        
        # å¹³å‡æ€§è´¨
        detail += f"""
## ğŸ“ˆ å¹³å‡æ€§è´¨

- **å¹³å‡åˆ†å­é‡**: {result['avg_mw']:.1f} Da
- **å¹³å‡ç±»è¯æ€§**: {result['avg_qed']:.3f}
- **å¹³å‡ LogP**: {result['avg_logp']:.2f}
"""
    else:
        detail += "\nâš ï¸ æ²¡æœ‰åˆ†å­é€šè¿‡ ADMET ç­›é€‰\n"
    
    return detail


def create_demo():
    """åˆ›å»ºæ¨¡å‹å¯¹æ¯”å›¾å½¢ç•Œé¢"""
    
    with gr.Blocks(
        title="LingNexus - æ¨¡å‹å¯¹æ¯”å·¥å…·",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown("""
# ğŸ”¬ LingNexus - AI æ¨¡å‹å¯¹æ¯”å·¥å…·

> åŒæ—¶æµ‹è¯•å¤šä¸ª LLM æ¨¡å‹çš„åˆ†å­ç”Ÿæˆèƒ½åŠ›ï¼Œç›´è§‚å¯¹æ¯”æ€§èƒ½å·®å¼‚
> 
> **æ”¯æŒæ¨¡å‹**: Qwen-Max / Gemini / DeepSeek
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ å¯¹æ¯”è®¾ç½®")
                
                target_input = gr.Textbox(
                    label="é¶ç‚¹åç§°",
                    placeholder="ä¾‹å¦‚ï¼šBTK, EGFR, JAK2",
                    value="BTK",
                    info="è¯·è¾“å…¥å…¬å¼€é¶ç‚¹åç§°"
                )
                
                with gr.Row():
                    model1_choice = gr.Dropdown(
                        label="æ¨¡å‹ 1",
                        choices=["qwen-max", "deepseek", "gemini"],
                        value="qwen-max",
                        info="ç¬¬ä¸€ä¸ªæµ‹è¯•æ¨¡å‹"
                    )
                    
                    model2_choice = gr.Dropdown(
                        label="æ¨¡å‹ 2",
                        choices=["qwen-max", "deepseek", "gemini"],
                        value="gemini",
                        info="ç¬¬äºŒä¸ªæµ‹è¯•æ¨¡å‹ (ğŸ”¥ gemini = Gemini 3 Pro)"
                    )
                
                requirements_input = gr.Textbox(
                    label="ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰",
                    placeholder="ä¾‹å¦‚ï¼šåˆ†å­é‡<400ï¼Œé«˜é€‰æ‹©æ€§",
                    lines=2
                )
                
                compare_btn = gr.Button(
                    "ğŸ”¬ å¼€å§‹å¯¹æ¯”",
                    variant="primary",
                    size="lg"
                )
                
                gr.Markdown("""
---
### ğŸ’¡ ä½¿ç”¨æç¤º

1. **é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹**è¿›è¡Œå¯¹æ¯”
2. **ä¸‰å¤§æ¨¡å‹**ï¼š
   - ğŸ‡¨ğŸ‡³ `qwen-max` = é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰
   - ğŸ§  `deepseek` = DeepSeek 3.2ï¼ˆæ¨ç†èƒ½åŠ›å¼ºï¼‰
   - ğŸ”¥ `gemini` = Gemini 3 Pro Previewï¼ˆæœ€æ–°æœ€å¼ºï¼‰
3. **æ¨èå¯¹æ¯”ç»„åˆ**ï¼š
   - Qwen-Max vs Geminiï¼ˆå›½äº§ vs å›½é™…ï¼‰
   - Qwen-Max vs DeepSeekï¼ˆå›½äº§åŒé›„ï¼‰
   - DeepSeek vs Geminiï¼ˆæ¨ç†å¯¹å†³ï¼‰Â·
4. **å¯¹æ¯”ç»´åº¦**ï¼šé€šè¿‡ç‡ã€QEDã€é€Ÿåº¦ã€è¾“å‡ºæ ¼å¼
                """)
        
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“Š å¯¹æ¯”ç»“æœ")
                
                with gr.Tab("ğŸ“Š å¯¹æ¯”æŠ¥å‘Š"):
                    report_output = gr.Markdown()
                
                with gr.Tab("ğŸ¤– æ¨¡å‹ 1 è¯¦æƒ…"):
                    model1_detail = gr.Markdown()
                
                with gr.Tab("ğŸ¤– æ¨¡å‹ 2 è¯¦æƒ…"):
                    model2_detail = gr.Markdown()
        
        # ç»‘å®šäº‹ä»¶
        compare_btn.click(
            fn=compare_models_ui,
            inputs=[target_input, model1_choice, model2_choice, requirements_input],
            outputs=[report_output, model1_detail, model2_detail]
        )
        
        # ç¤ºä¾‹
        gr.Markdown("""
---
### ğŸ§ª æ¨èæµ‹è¯•æ¡ˆä¾‹

| é¶ç‚¹ | è¯´æ˜ | æ¨èå¯¹æ¯” |
|------|------|---------|
| BTK | å¸ƒé²é¡¿é…ªæ°¨é…¸æ¿€é…¶ï¼ˆIbrutinib é¶ç‚¹ï¼‰ | Qwen-Max vs Gemini |
| EGFR | è¡¨çš®ç”Ÿé•¿å› å­å—ä½“ï¼ˆGefitinib é¶ç‚¹ï¼‰ | Qwen-Max vs DeepSeek |
| JAK2 | Janus æ¿€é…¶ 2ï¼ˆRuxolitinib é¶ç‚¹ï¼‰ | DeepSeek vs Gemini |

**âš ï¸ æ³¨æ„**: é¦–æ¬¡è¿è¡Œéœ€ç¡®ä¿å·²é…ç½®æ‰€æœ‰æ¨¡å‹çš„ API Keyï¼ˆè§ `config/model_config.json`ï¼‰
        """)
    
    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(
        server_name="127.0.0.1",
        server_port=7861,  # ä½¿ç”¨ä¸åŒç«¯å£é¿å…å†²çª
        share=False,
        show_error=True
    )
    print("\nâœ¨ LingNexus æ¨¡å‹å¯¹æ¯”å·¥å…·å·²å¯åŠ¨ï¼")
    print("ğŸŒ è®¿é—®åœ°å€ï¼šhttp://127.0.0.1:7861")
